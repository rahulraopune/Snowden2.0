{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA_Ex3_Argument_Assessment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python37364bit45a760422be94c8b9d8a395a722e388c",
      "display_name": "Python 3.7.3 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3"
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /Users/rahul/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /Users/rahul/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "import nltk\n",
        "import ssl\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "lst_stopwords = nltk.corpus.stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
        "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower().strip())\n",
        "\n",
        "    ## Tokenize (convert from string to list)\n",
        "    lst_text = text.split()\n",
        "    ## remove Stopwords\n",
        "    if lst_stopwords is not None:\n",
        "        lst_text = [word for word in lst_text if word not in \n",
        "                    lst_stopwords]\n",
        "\n",
        "    ## Stemming (remove -ing, -ly, ...)\n",
        "    if flg_stemm == True:\n",
        "        ps = nltk.stem.porter.PorterStemmer()\n",
        "        lst_text = [ps.stem(word) for word in lst_text]\n",
        "                \n",
        "    ## Lemmatisation (convert the word into root word)\n",
        "    if flg_lemm == True:\n",
        "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
        "\n",
        "    ## back to string from list\n",
        "    text = \" \".join(lst_text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "def fetch_all_neg_words():\n",
        "    list_neg_words = []\n",
        "    with open(\"neg_key_words.txt\",\"r\") as file:\n",
        "        for line in file:\n",
        "            list_neg_words.append(line.strip())\n",
        "    return list_neg_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_number_of_neg_words(doc):\n",
        "    list_neg_words = fetch_all_neg_words()\n",
        "    sum = 0\n",
        "    for token in doc:\n",
        "        if str(token) in list_neg_words:\n",
        "            sum += 1\n",
        "    return sum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_5resnXCiG4"
      },
      "source": [
        "#Used to read training data\n",
        "def read_data(filename):\n",
        "    train_df = pd.read_json(filename)\n",
        "    y_train = train_df['label']\n",
        "    body_train = []\n",
        "    contro_list = []\n",
        "    ups_list = []\n",
        "    viol_list = []\n",
        "    main_list = []\n",
        "    for i in range(0, len(train_df)):\n",
        "        id = train_df['id'][i]\n",
        "        size_of_posts_per_thread = len(train_df['preceding_posts'][i])\n",
        "        post_text = []\n",
        "        sum_contro = 0\n",
        "        sum_ups = 0\n",
        "        sum_viol = 0\n",
        "        for j in range(0, size_of_posts_per_thread): \n",
        "            text_body = train_df['preceding_posts'][i][j]['body']\n",
        "            sum_contro += train_df['preceding_posts'][i][j]['controversiality']\n",
        "            sum_ups += train_df['preceding_posts'][i][j]['ups']\n",
        "            sum_viol += train_df['preceding_posts'][i][j]['violated_rule']\n",
        "            post_text.append(text_body)\n",
        "        body_text = ' '.join(post_text)\n",
        "        preprocessed_body_text = utils_preprocess_text(body_text,lst_stopwords=lst_stopwords)\n",
        "        doc = nlp(preprocessed_body_text)\n",
        "        negative_keywords_count = get_number_of_neg_words(doc)\n",
        "        main_list.append({\n",
        "            \"id\":id,\n",
        "            \"body\":preprocessed_body_text, \n",
        "            \"controversiality\":sum_contro, \n",
        "            \"ups\":sum_ups, \n",
        "            \"violated_rule\":sum_viol,\n",
        "            \"negative_keywords_count\":negative_keywords_count,\n",
        "            \"vector\":doc.vector\n",
        "        })\n",
        "    X_df = pd.DataFrame(main_list)\n",
        "    return X_df, y_train"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "sjPjlSCX9IAa",
        "outputId": "00bc26f6-e8e4-477c-975f-39fe1103db2e"
      },
      "source": [
        "x_train, y_train = read_data(\"train-data-prepared.json\")\n",
        "x_val, y_val = read_data(\"val-data-prepared.json\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              id                                               body  \\\n",
              "0     t1_dggp3q9  right woman nonsexual creature would never use...   \n",
              "1     t1_dk3zd9h  making prostitution legal make much difficult ...   \n",
              "2     t1_d86bsqs  httpsenwikipediaorgwikifederalist_no_68 specif...   \n",
              "3     t1_cpzy2ya  real property logical absolute necessity regis...   \n",
              "4     t1_d92nfmh  really defending multinationals greedy try nes...   \n",
              "...          ...                                                ...   \n",
              "1931  t1_cpet2nu  totally right completely flubbed sure totally ...   \n",
              "1932  t1_ck91k4x  think argument fine principle number provide f...   \n",
              "1933  t1_ch7503g  im stuck debate month cant think right moral p...   \n",
              "1934  t1_denmvjy  even saying wasnt 100 false still doesnt make ...   \n",
              "1935  t1_crtmi2e  thing im sure universal policy unspoken defini...   \n",
              "\n",
              "      controversiality  ups  violated_rule  negative_keywords_count  \\\n",
              "0                    0    1              0                        2   \n",
              "1                    0   11              0                        1   \n",
              "2                    0    3              0                       12   \n",
              "3                    0    3              0                       31   \n",
              "4                    0    3              0                        8   \n",
              "...                ...  ...            ...                      ...   \n",
              "1931                 0    2              0                       51   \n",
              "1932                 0    3              5                       42   \n",
              "1933                 0    2              0                       29   \n",
              "1934                 0    8              0                        6   \n",
              "1935                 0    4              0                        5   \n",
              "\n",
              "                                                 vector  \n",
              "0     [0.6291083, 0.0771986, 0.19754855, -0.05052166...  \n",
              "1     [0.45894313, -0.06847714, 0.2195477, -0.068728...  \n",
              "2     [0.7297775, 0.21284659, 0.10354026, -0.1035865...  \n",
              "3     [0.49827892, 0.1120066, 0.12605643, -0.0839523...  \n",
              "4     [0.34527984, -0.051554915, 0.11279477, -0.0491...  \n",
              "...                                                 ...  \n",
              "1931  [0.38978824, 0.03186239, 0.12352137, -0.056145...  \n",
              "1932  [0.41911715, 0.121182114, 0.15129055, -0.08296...  \n",
              "1933  [0.26443037, -0.025680082, 0.18942213, -0.0466...  \n",
              "1934  [0.3212733, 0.100675665, 0.14381512, -0.024241...  \n",
              "1935  [0.092195876, -0.118038826, -0.08342235, -0.03...  \n",
              "\n",
              "[1936 rows x 7 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>body</th>\n      <th>controversiality</th>\n      <th>ups</th>\n      <th>violated_rule</th>\n      <th>negative_keywords_count</th>\n      <th>vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t1_dggp3q9</td>\n      <td>right woman nonsexual creature would never use...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[0.6291083, 0.0771986, 0.19754855, -0.05052166...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t1_dk3zd9h</td>\n      <td>making prostitution legal make much difficult ...</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[0.45894313, -0.06847714, 0.2195477, -0.068728...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t1_d86bsqs</td>\n      <td>httpsenwikipediaorgwikifederalist_no_68 specif...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>12</td>\n      <td>[0.7297775, 0.21284659, 0.10354026, -0.1035865...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t1_cpzy2ya</td>\n      <td>real property logical absolute necessity regis...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>31</td>\n      <td>[0.49827892, 0.1120066, 0.12605643, -0.0839523...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>t1_d92nfmh</td>\n      <td>really defending multinationals greedy try nes...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>8</td>\n      <td>[0.34527984, -0.051554915, 0.11279477, -0.0491...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1931</th>\n      <td>t1_cpet2nu</td>\n      <td>totally right completely flubbed sure totally ...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>51</td>\n      <td>[0.38978824, 0.03186239, 0.12352137, -0.056145...</td>\n    </tr>\n    <tr>\n      <th>1932</th>\n      <td>t1_ck91k4x</td>\n      <td>think argument fine principle number provide f...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>42</td>\n      <td>[0.41911715, 0.121182114, 0.15129055, -0.08296...</td>\n    </tr>\n    <tr>\n      <th>1933</th>\n      <td>t1_ch7503g</td>\n      <td>im stuck debate month cant think right moral p...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>29</td>\n      <td>[0.26443037, -0.025680082, 0.18942213, -0.0466...</td>\n    </tr>\n    <tr>\n      <th>1934</th>\n      <td>t1_denmvjy</td>\n      <td>even saying wasnt 100 false still doesnt make ...</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>6</td>\n      <td>[0.3212733, 0.100675665, 0.14381512, -0.024241...</td>\n    </tr>\n    <tr>\n      <th>1935</th>\n      <td>t1_crtmi2e</td>\n      <td>thing im sure universal policy unspoken defini...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5</td>\n      <td>[0.092195876, -0.118038826, -0.08342235, -0.03...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1936 rows Ã— 7 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_X(X_df):\n",
        "    X = []\n",
        "    for i in range(0, len(X_df)):\n",
        "        controversiality = X_df[\"controversiality\"][i]\n",
        "        ups = X_df[\"ups\"][i].item()\n",
        "        violated_rule = X_df[\"violated_rule\"][i].item()\n",
        "        negative_keywords_count = X_df[\"negative_keywords_count\"][i].item()\n",
        "        vector = X_df[\"vector\"][i].tolist()\n",
        "        vector.append(controversiality)\n",
        "        vector.append(ups)\n",
        "        vector.append(violated_rule)\n",
        "        vector.append(negative_keywords_count)\n",
        "        X.append(vector)\n",
        "    return np.array(X)\n",
        "\n",
        "X_train = generate_X(x_train)\n",
        "X_test = generate_X(x_val)\n",
        "\n",
        "y = y_train.to_numpy().T\n",
        "y_test = y_val.to_numpy().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6204081632653061"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "estimator = svm.SVC(kernel='rbf', C=100000)\n",
        "y_pred = estimator.fit(X_train,y).predict(X_test)\n",
        "f1_score(y_pred=y_pred, y_true=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5669291338582677"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "estimator = svm.SVC(kernel='linear')\n",
        "y_pred = estimator.fit(X_train,y).predict(X_test)\n",
        "f1_score(y_pred=y_pred, y_true=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}