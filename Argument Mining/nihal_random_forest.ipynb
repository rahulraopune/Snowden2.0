{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import en_core_web_sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_vector(text):\n",
    "    pos_feature_dict = {'ADJ':0, 'SPACE':0, 'ADV':0, 'INTJ':0, 'SYM':0, 'VERB':0, 'SCONJ':0, 'PART':0, 'X':0, 'PUNCT':0, 'AUX':0, 'ADP':0, 'NUM':0, 'PRON':0, 'NOUN':0, 'DET':0, 'CCONJ':0, 'PROPN':0}\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        pos = token.pos_\n",
    "        if pos in pos_feature_dict:\n",
    "            pos_feature_dict[pos] += 1\n",
    "        else:\n",
    "            pos_feature_dict[pos] = 1\n",
    "    vals_list = []\n",
    "    for k in list(pos_feature_dict.keys()):\n",
    "        vals_list.append(pos_feature_dict[k])\n",
    "    return vals_list\n",
    "\n",
    "\n",
    "def get_tag_vector(text):\n",
    "    pos_feature_dict = {'VBP':0, 'RBS':0, 'VBZ':0, 'WRB':0, 'VB':0, 'NNS':0, 'WDT':0, 'UH':0, '-RRB-':0, 'AFX':0, 'CC':0, 'WP':0, 'VBN':0, 'IN':0, 'PRP$':0, 'XX':0, 'WP$':0, 'RBR':0, 'PDT':0, 'HYPH':0, 'POS':0, '$':0, 'NNPS':0, 'MD':0, '.':0, 'VBD':0, 'JJR':0, 'NFP':0, ',':0, 'JJS':0, 'DT':0, '_SP':0, 'VBG':0, 'FW':0, 'RP':0, 'SYM':0, 'LS':0, 'CD':0, 'RB':0, 'EX':0, '``':0, 'PRP':0, \"''\":0, ':':0, 'TO':0, 'JJ':0, 'ADD':0, '-LRB-':0, 'NN':0, 'NNP':0}\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        pos = token.tag_\n",
    "        if pos in pos_feature_dict:\n",
    "            pos_feature_dict[pos] += 1\n",
    "        else:\n",
    "            pos_feature_dict[pos] = 1\n",
    "    vals_list = []\n",
    "    for k in list(pos_feature_dict.keys()):\n",
    "        vals_list.append(pos_feature_dict[k])\n",
    "    return vals_list\n",
    "\n",
    "def get_pos_tag_vector(text):\n",
    "    pos_vector = get_pos_vector(text)\n",
    "    tag_vector = get_tag_vector(text)\n",
    "    pos_vector.extend(tag_vector)\n",
    "    return pos_vector\n",
    "\n",
    "def get_set(text_list):\n",
    "    s = []\n",
    "    for text in text_list:\n",
    "        doc = nlp(text)\n",
    "        for token in doc:\n",
    "            pos = token.tag_\n",
    "            s.append(pos)\n",
    "    s = set(s)\n",
    "    print(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "y_test 0      1\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "344    1\n",
      "345    0\n",
      "346    0\n",
      "347    0\n",
      "348    0\n",
      "Name: label, Length: 349, dtype: int64\n",
      "y_pred [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "[[179  44]\n",
      " [ 83  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74       223\n",
      "           1       0.49      0.34      0.40       126\n",
      "\n",
      "    accuracy                           0.64       349\n",
      "   macro avg       0.59      0.57      0.57       349\n",
      "weighted avg       0.61      0.64      0.62       349\n",
      "\n",
      "0.6361031518624641\n"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "print(\"Random Forest\")\n",
    "\n",
    "#Training data\n",
    "df_train = pd.read_json('train-data-prepared.json')\n",
    "text_list = df_train['text'].to_list()\n",
    "vectors_list = [get_pos_tag_vector(text) for text in text_list]\n",
    "df_train['feature_vector'] = vectors_list\n",
    "y_train = df_train['label']\n",
    "X_train = np.stack(vectors_list,axis=0)\n",
    "X_train = normalize(X_train, axis=1, norm='l1')\n",
    "\n",
    "#Validation data\n",
    "df_test = pd.read_json('val-data-prepared.json')\n",
    "text_list = df_test['text'].to_list()\n",
    "vectors_list_test = [get_pos_tag_vector(text) for text in text_list]\n",
    "df_test['feature_vector'] = vectors_list_test\n",
    "X_test = np.stack(vectors_list_test,axis=0)\n",
    "X_test = normalize(X_test, axis=1, norm='l1')\n",
    "y_test = df_test['label']\n",
    "print(\"y_test {0}\".format(y_test))\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "y1_pred = []\n",
    "for x in y_pred:\n",
    "    if x > 0.50:\n",
    "        x=1\n",
    "        y1_pred.append(x)\n",
    "    else:\n",
    "        x=0\n",
    "        y1_pred.append(x)\n",
    "\n",
    "print(\"y_pred {0}\".format(y1_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y1_pred))\n",
    "print(classification_report(y_test,y1_pred))\n",
    "print(accuracy_score(y_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
